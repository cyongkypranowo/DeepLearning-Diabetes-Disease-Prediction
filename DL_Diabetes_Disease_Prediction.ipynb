{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4S7ag1LNq7tB0wX9v7A+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyongkypranowo/DeepLearning-Diabetes-Disease-Prediction/blob/main/DL_Diabetes_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project : Diabetes Disease Prediction\n",
        "##### Industri : Healthcare"
      ],
      "metadata": {
        "id": "JKGKQqm0AVfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective\n",
        "Sistem cerdas yang mampu mendeteksi potensi penyakit diabetes pada pasien wanita di Amerika Utara (Pima Indians).\n",
        "\n",
        "Sumber Data : [link](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)"
      ],
      "metadata": {
        "id": "dLYrExpoA7vf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Business & Data Understanding"
      ],
      "metadata": {
        "id": "qUiB3StYBX-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Understanding"
      ],
      "metadata": {
        "id": "rl6sj9dRBp3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Latar Belakang Proyek\n",
        "\n",
        "Di Indonesia, industri healthcare terus berkembang dan mengintegrasikan teknologi terkini untuk meningkatkan diagnosis dan perawatan. Sistem cerdas untuk prediksi diabetes sangat penting karena dapat memberikan deteksi dini, memungkinkan intervensi lebih cepat untuk mencegah komplikasi serius."
      ],
      "metadata": {
        "id": "9F9KY2X2BtUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Manfaat** : Deep learning mampu memproses dan belajar dari set data kesehatan yang kompleks, meningkatkan akurasi diagnostik penyakit diabetes dibandingkan metode tradisional. Ini memungkinkan deteksi dini dan lebih akurat dari kondisi prediabetes dan diabetes.\n",
        "2. **Harapan** : Penelitian ini juga dapat membuka jalan untuk penelitian lebih lanjut dalam penerapan teknologi AI dan machine learning dalam bidang medis lainnya, mendorong inovasi dalam diagnosa dan perawatan penyakit."
      ],
      "metadata": {
        "id": "_SGCgl5RDUfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tujuan Proyek\n",
        "Untuk mengembangkan dan mengimplementasikan sistem prediksi penyakit diabetes yang akurat dan efisien menggunakan teknologi deep learning, guna meningkatkan deteksi dini dan personalisasi perawatan bagi pasien diabetes."
      ],
      "metadata": {
        "id": "CkuePUU8DdAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Understanding"
      ],
      "metadata": {
        "id": "ah0OgqxZD_Qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deskripsi Dataset"
      ],
      "metadata": {
        "id": "Tk2r9kmXEBhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset ini terdiri dari 768 baris dengan 9 kolom, yang mencakup:\n",
        "\n",
        "* Pregnancies: Jumlah kehamilan.\n",
        "* Glucose: Konsentrasi glukosa plasma 2 jam dalam tes toleransi glukosa oral.\n",
        "* BloodPressure: Tekanan darah diastolik (mm Hg).\n",
        "* SkinThickness: Ketebalan lipatan kulit trisep (mm).\n",
        "* Insulin: Insulin serum 2 jam (mu U/ml).\n",
        "* BMI: Indeks massa tubuh (berat dalam kg/(tinggi dalam m)^2).\n",
        "* DiabetesPedigreeFunction: Fungsi silsilah diabetes, sebuah skor yang * merefleksikan kemungkinan genetik diabetes berdasarkan riwayat keluarga.\n",
        "* Age: Umur dalam tahun.\n",
        "* Outcome: Variabel kelas yang menandakan apakah subjek memiliki diabetes (1) atau tidak (0)."
      ],
      "metadata": {
        "id": "DLTg7ubmE-f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79_nO3wGpI5_",
        "outputId": "5f1cbffd-f2d7-4985-c284-d43f9bc2de25"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ESsTuv2o_232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41abc3d1-2418-443b-93a3-e21df489d82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-cff5ab87a437>:13: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ],
      "source": [
        "# Import library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner import HyperModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "df = pd.read_csv('diabetes.csv')"
      ],
      "metadata": {
        "id": "cn9Kpu_pFzJ-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan 5 baris pertama untuk melihat struktur datanya\n",
        "print(\"Struktur Data:\")\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHycz0s7F7N0",
        "outputId": "6f1cc51f-4bbe-4d92-989f-2fc62f0b5da6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Struktur Data:\n",
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "5            5      116             74              0        0  25.6   \n",
            "6            3       78             50             32       88  31.0   \n",
            "7           10      115              0              0        0  35.3   \n",
            "8            2      197             70             45      543  30.5   \n",
            "9            8      125             96              0        0   0.0   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "5                     0.201   30        0  \n",
            "6                     0.248   26        1  \n",
            "7                     0.134   29        0  \n",
            "8                     0.158   53        1  \n",
            "9                     0.232   54        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistik Deskriptif\n",
        "print(\"\\nStatistik Deskriptif:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNZk2LO-F850",
        "outputId": "ef94775f-3de1-4b42-f6a9-9266fc3edde9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Statistik Deskriptif:\n",
            "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
            "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
            "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
            "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
            "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
            "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
            "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
            "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
            "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
            "\n",
            "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
            "count  768.000000                768.000000  768.000000  768.000000  \n",
            "mean    31.992578                  0.471876   33.240885    0.348958  \n",
            "std      7.884160                  0.331329   11.760232    0.476951  \n",
            "min      0.000000                  0.078000   21.000000    0.000000  \n",
            "25%     27.300000                  0.243750   24.000000    0.000000  \n",
            "50%     32.000000                  0.372500   29.000000    0.000000  \n",
            "75%     36.600000                  0.626250   41.000000    1.000000  \n",
            "max     67.100000                  2.420000   81.000000    1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informasi Dataset\n",
        "print(\"\\nInformasi Dataset:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwTvU8JtGA6h",
        "outputId": "1bfbd28f-36ea-4540-d79d-dc5ee3dab33a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Informasi Dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ukuran Dataset\n",
        "print(\"\\nUkuran Dataset:\")\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CtKaJ7_GBGQ",
        "outputId": "7ecc534d-05f2-4b5e-b8ca-2fdd8432125a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ukuran Dataset:\n",
            "(768, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribusi Outcome (Hasil)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Outcome', data=df)\n",
        "plt.title('Distribusi Hasil Diabetes (0: Tidak, 1: Ya)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "IeFxpaD-GPUy",
        "outputId": "81f60ae4-3cdd-4648-84af-6f5c6b51783d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribusi Glukosa\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(df['Glucose'], kde=True)\n",
        "plt.title('Distribusi Konsentrasi Glukosa')\n",
        "plt.xlabel('Konsentrasi Glukosa')\n",
        "plt.ylabel('Frekuensi')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "nly4Hq_NG47C",
        "outputId": "fc60718a-3234-4b09-b235-7d13b5480880"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Cleaning & Analysis"
      ],
      "metadata": {
        "id": "8JLGsXtxHMEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kolom yang perlu dihandle nilai 0-nya\n",
        "columns_to_replace_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']"
      ],
      "metadata": {
        "id": "Wff-L3F6IcLn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ganti nilai 0 dengan median\n",
        "for column in columns_to_replace_zero:\n",
        "    df[column] = df[column].replace(0, df[column].median())"
      ],
      "metadata": {
        "id": "9cqzzEPZIihz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek ulang statistik deskriptif\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ljsmkodLIl02",
        "outputId": "ac2773ef-4943-4dbd-b187-b63267510304"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  121.656250      72.386719      27.334635   94.652344   \n",
              "std       3.369578   30.438286      12.096642       9.229014  105.547598   \n",
              "min       0.000000   44.000000      24.000000       7.000000   14.000000   \n",
              "25%       1.000000   99.750000      64.000000      23.000000   30.500000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   31.250000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    32.450911                  0.471876   33.240885    0.348958  \n",
              "std      6.875366                  0.331329   11.760232    0.476951  \n",
              "min     18.200000                  0.078000   21.000000    0.000000  \n",
              "25%     27.500000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dca7a9f-e30d-4794-b96e-4e4e192cefbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>121.656250</td>\n",
              "      <td>72.386719</td>\n",
              "      <td>27.334635</td>\n",
              "      <td>94.652344</td>\n",
              "      <td>32.450911</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>30.438286</td>\n",
              "      <td>12.096642</td>\n",
              "      <td>9.229014</td>\n",
              "      <td>105.547598</td>\n",
              "      <td>6.875366</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.200000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.750000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dca7a9f-e30d-4794-b96e-4e4e192cefbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1dca7a9f-e30d-4794-b96e-4e4e192cefbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1dca7a9f-e30d-4794-b96e-4e4e192cefbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a267b7c-5b11-43d7-9a3d-9d740f36ca1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a267b7c-5b11-43d7-9a3d-9d740f36ca1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a267b7c-5b11-43d7-9a3d-9d740f36ca1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 269.85223453356366,\n        \"min\": 0.0,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.8450520833333335,\n          3.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 239.51168557183297,\n        \"min\": 30.43828582241517,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          121.65625,\n          117.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 251.2764376086552,\n        \"min\": 12.096641733978139,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          72.38671875,\n          72.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 261.97903291393493,\n        \"min\": 7.0,\n        \"max\": 768.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          768.0,\n          27.334635416666668,\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 345.43922059327565,\n        \"min\": 14.0,\n        \"max\": 846.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          94.65234375,\n          31.25,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260.9543845566356,\n        \"min\": 6.875366469974719,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          32.45091145833333,\n          32.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 271.3005221658502,\n        \"min\": 0.078,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.47187630208333325,\n          0.3725,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260.1941178528413,\n        \"min\": 11.760231540678685,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          33.240885416666664,\n          29.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 271.3865920388932,\n        \"min\": 0.0,\n        \"max\": 768.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3489583333333333,\n          1.0,\n          0.47695137724279896\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis Data\n",
        "Setelah mengganti nilai 0 dengan median pada kolom **Glucose, BloodPressure, SkinThickness, Insulin, dan BMI**, kita dapat melihat beberapa perubahan dalam statistik deskriptif dataset:\n",
        "\n",
        "1. **Mean (Rata-rata):**\n",
        "Rata-rata untuk Glucose, BloodPressure, SkinThickness, Insulin, dan BMI kini lebih mewakili data karena tidak lagi terdampak oleh nilai 0 yang tidak realistis. Misalnya, rata-rata Insulin meningkat dari nilai sebelumnya menjadi 94.65, mengindikasikan penggantian nilai 0 dengan median memberikan representasi yang lebih akurat terhadap distribusi insulin dalam dataset.\n",
        "\n",
        "2. **Std (Standar Deviasi):**\n",
        "Standar deviasi untuk kolom yang diubah mengalami penyesuaian, menunjukkan variasi dalam data yang sebenarnya setelah penggantian nilai 0. Perubahan ini penting karena menunjukkan sebaran data yang lebih realistis.\n",
        "\n",
        "3. **Min (Minimum)**:\n",
        "Nilai minimum untuk kolom tersebut sekarang lebih realistis dan tidak lagi 0, yang menunjukkan bahwa penggantian nilai telah berhasil mengeliminasi nilai-nilai yang tidak mungkin secara klinis.\n",
        "\n",
        "4. **Median**:\n",
        "Median (50%) tidak berubah untuk beberapa kolom karena penggantian nilai 0 dengan median tidak mempengaruhi nilai tengah distribusi, kecuali jika sebagian besar data pada kolom tersebut adalah 0.\n",
        "\n",
        "5. **Perubahan pada Q1 dan Q3 (Kuartil 1 dan 3):**\n",
        "Kuartil pertama dan ketiga menunjukkan bagaimana sebaran data terbagi sebelum dan setelah titik median. Perubahan pada kuartil menunjukkan penyesuaian dalam distribusi data setelah nilai 0 diganti.\n",
        "Analisis ini menunjukkan bahwa penggantian nilai 0 dengan median telah membantu dalam memperbaiki kualitas dataset dengan mengeliminasi nilai-nilai yang tidak mungkin secara klinis, yang dapat meningkatkan kinerja model prediktif yang akan dibangun"
      ],
      "metadata": {
        "id": "E9VSvcDYJjN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformation Data"
      ],
      "metadata": {
        "id": "LkKr_MDxLguD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi dataset menjadi fitur dan target\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Membagi data menjadi set pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "SOsRsTbMLjw8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Modeling & Experiment Arsitektur Neural Network\n"
      ],
      "metadata": {
        "id": "2q9tZcJeKo8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Narrow Shallow Model\n",
        "(Memiliki sedikit lapisan dan sedikit\n",
        "neuron per lapisan)"
      ],
      "metadata": {
        "id": "opXcBImgpn5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ns = Sequential()\n",
        "model_ns.add(Dense(units=2, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_ns.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model_ns.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_ns.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "model_ns.summary()\n",
        "\n",
        "loss, accuracy = model_ns.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sZYvZtGvyH2",
        "outputId": "9d88b3e3-ec16-4268-c59c-d6e6ce5f163e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 0.7428 - accuracy: 0.7026 - val_loss: 0.7289 - val_accuracy: 0.6911\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7269 - accuracy: 0.7088 - val_loss: 0.7126 - val_accuracy: 0.6911\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7103 - accuracy: 0.7088 - val_loss: 0.6984 - val_accuracy: 0.7154\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6954 - accuracy: 0.7067 - val_loss: 0.6850 - val_accuracy: 0.7073\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6810 - accuracy: 0.7047 - val_loss: 0.6732 - val_accuracy: 0.7154\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6677 - accuracy: 0.7026 - val_loss: 0.6612 - val_accuracy: 0.6992\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.7026 - val_loss: 0.6512 - val_accuracy: 0.6911\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.7026 - val_loss: 0.6420 - val_accuracy: 0.6748\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6986 - val_loss: 0.6332 - val_accuracy: 0.6667\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6229 - accuracy: 0.7067 - val_loss: 0.6259 - val_accuracy: 0.6585\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7108 - val_loss: 0.6195 - val_accuracy: 0.6748\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7067 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.7088 - val_loss: 0.6078 - val_accuracy: 0.6748\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7149 - val_loss: 0.6034 - val_accuracy: 0.6829\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7149 - val_loss: 0.5994 - val_accuracy: 0.6911\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.7108 - val_loss: 0.5956 - val_accuracy: 0.6911\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.7230 - val_loss: 0.5915 - val_accuracy: 0.6829\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7251 - val_loss: 0.5878 - val_accuracy: 0.6911\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7271 - val_loss: 0.5846 - val_accuracy: 0.6992\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.7271 - val_loss: 0.5821 - val_accuracy: 0.6911\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7271 - val_loss: 0.5791 - val_accuracy: 0.6992\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7271 - val_loss: 0.5765 - val_accuracy: 0.6992\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7352 - val_loss: 0.5748 - val_accuracy: 0.6992\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.7352 - val_loss: 0.5726 - val_accuracy: 0.6992\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.7352 - val_loss: 0.5705 - val_accuracy: 0.6911\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.7352 - val_loss: 0.5687 - val_accuracy: 0.6911\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7352 - val_loss: 0.5666 - val_accuracy: 0.6911\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7373 - val_loss: 0.5638 - val_accuracy: 0.6911\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7393 - val_loss: 0.5617 - val_accuracy: 0.6911\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7393 - val_loss: 0.5593 - val_accuracy: 0.6911\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7413 - val_loss: 0.5574 - val_accuracy: 0.6992\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7434 - val_loss: 0.5553 - val_accuracy: 0.6992\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7454 - val_loss: 0.5533 - val_accuracy: 0.6992\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7454 - val_loss: 0.5513 - val_accuracy: 0.6992\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7454 - val_loss: 0.5492 - val_accuracy: 0.7073\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7454 - val_loss: 0.5473 - val_accuracy: 0.7073\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7434 - val_loss: 0.5452 - val_accuracy: 0.7073\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7393 - val_loss: 0.5434 - val_accuracy: 0.7073\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5282 - accuracy: 0.7393 - val_loss: 0.5417 - val_accuracy: 0.7073\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5268 - accuracy: 0.7413 - val_loss: 0.5394 - val_accuracy: 0.7073\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5253 - accuracy: 0.7413 - val_loss: 0.5374 - val_accuracy: 0.7154\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7475 - val_loss: 0.5351 - val_accuracy: 0.7154\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.7495 - val_loss: 0.5334 - val_accuracy: 0.7236\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5216 - accuracy: 0.7495 - val_loss: 0.5314 - val_accuracy: 0.7236\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.7495 - val_loss: 0.5301 - val_accuracy: 0.7236\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7495 - val_loss: 0.5288 - val_accuracy: 0.7236\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5182 - accuracy: 0.7515 - val_loss: 0.5272 - val_accuracy: 0.7236\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5171 - accuracy: 0.7515 - val_loss: 0.5253 - val_accuracy: 0.7236\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.5159 - accuracy: 0.7515 - val_loss: 0.5237 - val_accuracy: 0.7236\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5147 - accuracy: 0.7515 - val_loss: 0.5216 - val_accuracy: 0.7236\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5137 - accuracy: 0.7515 - val_loss: 0.5202 - val_accuracy: 0.7236\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.7515 - val_loss: 0.5193 - val_accuracy: 0.7236\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5115 - accuracy: 0.7515 - val_loss: 0.5180 - val_accuracy: 0.7236\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5105 - accuracy: 0.7515 - val_loss: 0.5167 - val_accuracy: 0.7236\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5095 - accuracy: 0.7556 - val_loss: 0.5157 - val_accuracy: 0.7236\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5086 - accuracy: 0.7597 - val_loss: 0.5149 - val_accuracy: 0.7154\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5078 - accuracy: 0.7576 - val_loss: 0.5135 - val_accuracy: 0.7236\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5069 - accuracy: 0.7556 - val_loss: 0.5131 - val_accuracy: 0.7236\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5061 - accuracy: 0.7556 - val_loss: 0.5120 - val_accuracy: 0.7398\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7556 - val_loss: 0.5111 - val_accuracy: 0.7480\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5044 - accuracy: 0.7556 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5038 - accuracy: 0.7556 - val_loss: 0.5098 - val_accuracy: 0.7480\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5028 - accuracy: 0.7576 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.7576 - val_loss: 0.5084 - val_accuracy: 0.7480\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.5012 - accuracy: 0.7617 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5005 - accuracy: 0.7678 - val_loss: 0.5070 - val_accuracy: 0.7561\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4998 - accuracy: 0.7699 - val_loss: 0.5060 - val_accuracy: 0.7561\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4992 - accuracy: 0.7719 - val_loss: 0.5054 - val_accuracy: 0.7561\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4984 - accuracy: 0.7719 - val_loss: 0.5047 - val_accuracy: 0.7561\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.7719 - val_loss: 0.5043 - val_accuracy: 0.7642\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.4971 - accuracy: 0.7678 - val_loss: 0.5041 - val_accuracy: 0.7642\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4967 - accuracy: 0.7678 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4961 - accuracy: 0.7658 - val_loss: 0.5029 - val_accuracy: 0.7642\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4955 - accuracy: 0.7658 - val_loss: 0.5022 - val_accuracy: 0.7642\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4949 - accuracy: 0.7637 - val_loss: 0.5019 - val_accuracy: 0.7561\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.4943 - accuracy: 0.7637 - val_loss: 0.5017 - val_accuracy: 0.7561\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4938 - accuracy: 0.7637 - val_loss: 0.5012 - val_accuracy: 0.7561\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.4931 - accuracy: 0.7637 - val_loss: 0.5006 - val_accuracy: 0.7561\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 32ms/step - loss: 0.4927 - accuracy: 0.7678 - val_loss: 0.5004 - val_accuracy: 0.7561\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.4923 - accuracy: 0.7658 - val_loss: 0.5000 - val_accuracy: 0.7561\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.4917 - accuracy: 0.7658 - val_loss: 0.4996 - val_accuracy: 0.7561\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.4914 - accuracy: 0.7678 - val_loss: 0.4992 - val_accuracy: 0.7561\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4908 - accuracy: 0.7678 - val_loss: 0.4987 - val_accuracy: 0.7561\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.4902 - accuracy: 0.7678 - val_loss: 0.4986 - val_accuracy: 0.7724\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4898 - accuracy: 0.7699 - val_loss: 0.4979 - val_accuracy: 0.7724\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4892 - accuracy: 0.7678 - val_loss: 0.4972 - val_accuracy: 0.7724\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4888 - accuracy: 0.7678 - val_loss: 0.4970 - val_accuracy: 0.7724\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4885 - accuracy: 0.7699 - val_loss: 0.4968 - val_accuracy: 0.7724\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4882 - accuracy: 0.7699 - val_loss: 0.4966 - val_accuracy: 0.7724\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4878 - accuracy: 0.7719 - val_loss: 0.4959 - val_accuracy: 0.7724\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4874 - accuracy: 0.7739 - val_loss: 0.4955 - val_accuracy: 0.7724\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4870 - accuracy: 0.7739 - val_loss: 0.4947 - val_accuracy: 0.7724\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4866 - accuracy: 0.7699 - val_loss: 0.4944 - val_accuracy: 0.7724\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4862 - accuracy: 0.7699 - val_loss: 0.4941 - val_accuracy: 0.7724\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4860 - accuracy: 0.7699 - val_loss: 0.4936 - val_accuracy: 0.7724\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4857 - accuracy: 0.7699 - val_loss: 0.4933 - val_accuracy: 0.7724\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4854 - accuracy: 0.7719 - val_loss: 0.4932 - val_accuracy: 0.7724\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4850 - accuracy: 0.7719 - val_loss: 0.4928 - val_accuracy: 0.7724\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4849 - accuracy: 0.7739 - val_loss: 0.4927 - val_accuracy: 0.7724\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4845 - accuracy: 0.7739 - val_loss: 0.4923 - val_accuracy: 0.7724\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5131 - accuracy: 0.7338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Narrow Wide Model\n",
        "(Memiliki sedikit lapisan tetapi dengan\n",
        "lebih banyak neuron per lapisan)"
      ],
      "metadata": {
        "id": "PrmkPAVyRy6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_nw = Sequential()\n",
        "model_nw.add(Dense(units=128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_nw.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model_nw.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_nw.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "model_nw.summary()\n",
        "\n",
        "loss, accuracy = model_nw.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_PFOpSHSJvw",
        "outputId": "745537e3-ab3f-4209-9ada-8b119a19cc43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 3s 39ms/step - loss: 0.6497 - accuracy: 0.6741 - val_loss: 0.6026 - val_accuracy: 0.6992\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.5604 - accuracy: 0.7495 - val_loss: 0.5471 - val_accuracy: 0.7073\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.5135 - accuracy: 0.7617 - val_loss: 0.5164 - val_accuracy: 0.7317\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4885 - accuracy: 0.7678 - val_loss: 0.4980 - val_accuracy: 0.7317\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4721 - accuracy: 0.7739 - val_loss: 0.4864 - val_accuracy: 0.7398\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4800 - val_accuracy: 0.7398\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.4534 - accuracy: 0.7841 - val_loss: 0.4742 - val_accuracy: 0.7642\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.4464 - accuracy: 0.7862 - val_loss: 0.4688 - val_accuracy: 0.7642\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.4415 - accuracy: 0.7841 - val_loss: 0.4685 - val_accuracy: 0.7724\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.4368 - accuracy: 0.7841 - val_loss: 0.4662 - val_accuracy: 0.7724\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4330 - accuracy: 0.7862 - val_loss: 0.4648 - val_accuracy: 0.7642\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.4298 - accuracy: 0.7841 - val_loss: 0.4662 - val_accuracy: 0.7642\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.4268 - accuracy: 0.7862 - val_loss: 0.4643 - val_accuracy: 0.7561\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.4240 - accuracy: 0.7862 - val_loss: 0.4631 - val_accuracy: 0.7642\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4220 - accuracy: 0.7862 - val_loss: 0.4623 - val_accuracy: 0.7561\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4208 - accuracy: 0.7862 - val_loss: 0.4599 - val_accuracy: 0.7561\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4174 - accuracy: 0.7862 - val_loss: 0.4631 - val_accuracy: 0.7480\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.4165 - accuracy: 0.7882 - val_loss: 0.4655 - val_accuracy: 0.7480\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4142 - accuracy: 0.7882 - val_loss: 0.4624 - val_accuracy: 0.7480\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4128 - accuracy: 0.7862 - val_loss: 0.4613 - val_accuracy: 0.7561\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.4103 - accuracy: 0.7882 - val_loss: 0.4609 - val_accuracy: 0.7561\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4093 - accuracy: 0.7923 - val_loss: 0.4624 - val_accuracy: 0.7561\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.4086 - accuracy: 0.7882 - val_loss: 0.4641 - val_accuracy: 0.7480\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4069 - accuracy: 0.7943 - val_loss: 0.4641 - val_accuracy: 0.7480\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.4060 - accuracy: 0.7902 - val_loss: 0.4607 - val_accuracy: 0.7561\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.4039 - accuracy: 0.7943 - val_loss: 0.4626 - val_accuracy: 0.7480\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.4025 - accuracy: 0.7923 - val_loss: 0.4626 - val_accuracy: 0.7561\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.4017 - accuracy: 0.7862 - val_loss: 0.4627 - val_accuracy: 0.7642\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.3995 - accuracy: 0.7984 - val_loss: 0.4633 - val_accuracy: 0.7561\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4004 - accuracy: 0.7943 - val_loss: 0.4680 - val_accuracy: 0.7561\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.3973 - accuracy: 0.7943 - val_loss: 0.4670 - val_accuracy: 0.7642\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3968 - accuracy: 0.8004 - val_loss: 0.4647 - val_accuracy: 0.7642\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3955 - accuracy: 0.8004 - val_loss: 0.4673 - val_accuracy: 0.7642\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3946 - accuracy: 0.8106 - val_loss: 0.4667 - val_accuracy: 0.7724\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.3929 - accuracy: 0.8086 - val_loss: 0.4658 - val_accuracy: 0.7642\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3922 - accuracy: 0.8065 - val_loss: 0.4646 - val_accuracy: 0.7642\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.3910 - accuracy: 0.8086 - val_loss: 0.4646 - val_accuracy: 0.7724\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.3910 - accuracy: 0.8065 - val_loss: 0.4640 - val_accuracy: 0.7724\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3905 - accuracy: 0.8065 - val_loss: 0.4663 - val_accuracy: 0.7561\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8086 - val_loss: 0.4650 - val_accuracy: 0.7642\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3876 - accuracy: 0.8167 - val_loss: 0.4638 - val_accuracy: 0.7724\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.3860 - accuracy: 0.8126 - val_loss: 0.4658 - val_accuracy: 0.7724\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.3856 - accuracy: 0.8147 - val_loss: 0.4684 - val_accuracy: 0.7724\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.3852 - accuracy: 0.8208 - val_loss: 0.4672 - val_accuracy: 0.7642\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.3845 - accuracy: 0.8187 - val_loss: 0.4681 - val_accuracy: 0.7724\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.3840 - accuracy: 0.8187 - val_loss: 0.4693 - val_accuracy: 0.7805\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.3824 - accuracy: 0.8126 - val_loss: 0.4685 - val_accuracy: 0.7724\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.3812 - accuracy: 0.8208 - val_loss: 0.4694 - val_accuracy: 0.7724\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.3804 - accuracy: 0.8187 - val_loss: 0.4704 - val_accuracy: 0.7805\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3793 - accuracy: 0.8187 - val_loss: 0.4680 - val_accuracy: 0.7724\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3792 - accuracy: 0.8106 - val_loss: 0.4705 - val_accuracy: 0.7642\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.3797 - accuracy: 0.8167 - val_loss: 0.4695 - val_accuracy: 0.7642\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.3774 - accuracy: 0.8106 - val_loss: 0.4713 - val_accuracy: 0.7642\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3769 - accuracy: 0.8167 - val_loss: 0.4720 - val_accuracy: 0.7724\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.3756 - accuracy: 0.8187 - val_loss: 0.4713 - val_accuracy: 0.7642\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3748 - accuracy: 0.8147 - val_loss: 0.4728 - val_accuracy: 0.7561\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3740 - accuracy: 0.8167 - val_loss: 0.4740 - val_accuracy: 0.7642\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.3741 - accuracy: 0.8147 - val_loss: 0.4761 - val_accuracy: 0.7724\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.3724 - accuracy: 0.8147 - val_loss: 0.4726 - val_accuracy: 0.7642\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.3721 - accuracy: 0.8167 - val_loss: 0.4724 - val_accuracy: 0.7642\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3715 - accuracy: 0.8147 - val_loss: 0.4768 - val_accuracy: 0.7724\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3714 - accuracy: 0.8167 - val_loss: 0.4766 - val_accuracy: 0.7642\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3714 - accuracy: 0.8187 - val_loss: 0.4771 - val_accuracy: 0.7642\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3706 - accuracy: 0.8147 - val_loss: 0.4776 - val_accuracy: 0.7561\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.3685 - accuracy: 0.8167 - val_loss: 0.4772 - val_accuracy: 0.7642\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3673 - accuracy: 0.8208 - val_loss: 0.4767 - val_accuracy: 0.7642\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3678 - accuracy: 0.8310 - val_loss: 0.4767 - val_accuracy: 0.7642\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3669 - accuracy: 0.8289 - val_loss: 0.4805 - val_accuracy: 0.7642\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3662 - accuracy: 0.8187 - val_loss: 0.4795 - val_accuracy: 0.7642\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.8228 - val_loss: 0.4823 - val_accuracy: 0.7642\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3648 - accuracy: 0.8208 - val_loss: 0.4819 - val_accuracy: 0.7642\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3640 - accuracy: 0.8228 - val_loss: 0.4822 - val_accuracy: 0.7561\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 0.8228 - val_loss: 0.4820 - val_accuracy: 0.7642\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8228 - val_loss: 0.4843 - val_accuracy: 0.7642\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8269 - val_loss: 0.4823 - val_accuracy: 0.7642\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8289 - val_loss: 0.4835 - val_accuracy: 0.7642\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8269 - val_loss: 0.4850 - val_accuracy: 0.7642\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3611 - accuracy: 0.8269 - val_loss: 0.4832 - val_accuracy: 0.7642\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8289 - val_loss: 0.4795 - val_accuracy: 0.7642\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3598 - accuracy: 0.8310 - val_loss: 0.4807 - val_accuracy: 0.7642\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.3587 - accuracy: 0.8350 - val_loss: 0.4811 - val_accuracy: 0.7642\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3579 - accuracy: 0.8289 - val_loss: 0.4825 - val_accuracy: 0.7642\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3582 - accuracy: 0.8289 - val_loss: 0.4848 - val_accuracy: 0.7480\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8248 - val_loss: 0.4864 - val_accuracy: 0.7642\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8350 - val_loss: 0.4877 - val_accuracy: 0.7642\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8330 - val_loss: 0.4834 - val_accuracy: 0.7642\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3563 - accuracy: 0.8371 - val_loss: 0.4856 - val_accuracy: 0.7561\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8310 - val_loss: 0.4905 - val_accuracy: 0.7561\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8350 - val_loss: 0.4894 - val_accuracy: 0.7561\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8350 - val_loss: 0.4889 - val_accuracy: 0.7642\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8310 - val_loss: 0.4885 - val_accuracy: 0.7642\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8350 - val_loss: 0.4880 - val_accuracy: 0.7480\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8330 - val_loss: 0.4879 - val_accuracy: 0.7561\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8310 - val_loss: 0.4922 - val_accuracy: 0.7561\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8391 - val_loss: 0.4894 - val_accuracy: 0.7642\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8391 - val_loss: 0.4879 - val_accuracy: 0.7561\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8371 - val_loss: 0.4924 - val_accuracy: 0.7480\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8371 - val_loss: 0.4942 - val_accuracy: 0.7561\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8269 - val_loss: 0.4883 - val_accuracy: 0.7561\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8350 - val_loss: 0.4899 - val_accuracy: 0.7642\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 128)               1152      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1281 (5.00 KB)\n",
            "Trainable params: 1281 (5.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep And Shallow\n",
        "(Memiliki sedikit lapisan tetapi dengan\n",
        "lebih banyak neuron per lapisan)"
      ],
      "metadata": {
        "id": "fI2z_MJgkLpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ds = Sequential()\n",
        "model_ds.add(Dense(units=4, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_ds.add(Dense(units=4, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_ds.add(Dense(units=2, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_ds.add(Dense(units=2, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_ds.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model_ds.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_ds.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "model_ds.summary()\n",
        "\n",
        "loss, accuracy = model_ds.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4y7hBuLkQO2",
        "outputId": "2f206aeb-e3e1-412a-cb29-7cecfa86cbe9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 0.6792 - accuracy: 0.6640 - val_loss: 0.6818 - val_accuracy: 0.6098\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.6640 - val_loss: 0.6760 - val_accuracy: 0.6098\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.6640 - val_loss: 0.6692 - val_accuracy: 0.6098\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.6640 - val_loss: 0.6616 - val_accuracy: 0.6098\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6640 - val_loss: 0.6527 - val_accuracy: 0.6098\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6640 - val_loss: 0.6431 - val_accuracy: 0.6098\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6209 - accuracy: 0.6640 - val_loss: 0.6329 - val_accuracy: 0.6098\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6640 - val_loss: 0.6219 - val_accuracy: 0.6098\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.6640 - val_loss: 0.6122 - val_accuracy: 0.6098\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.6640 - val_loss: 0.6031 - val_accuracy: 0.6098\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.6640 - val_loss: 0.5960 - val_accuracy: 0.6098\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.6640 - val_loss: 0.5896 - val_accuracy: 0.6098\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.6640 - val_loss: 0.5834 - val_accuracy: 0.6098\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.6640 - val_loss: 0.5783 - val_accuracy: 0.6098\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.6640 - val_loss: 0.5735 - val_accuracy: 0.6098\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.6640 - val_loss: 0.5686 - val_accuracy: 0.6098\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.6640 - val_loss: 0.5639 - val_accuracy: 0.6098\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.6640 - val_loss: 0.5593 - val_accuracy: 0.6098\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.6640 - val_loss: 0.5558 - val_accuracy: 0.6098\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.6640 - val_loss: 0.5521 - val_accuracy: 0.6098\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.6640 - val_loss: 0.5480 - val_accuracy: 0.6098\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.6640 - val_loss: 0.5456 - val_accuracy: 0.6098\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.6640 - val_loss: 0.5424 - val_accuracy: 0.6098\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.6640 - val_loss: 0.5394 - val_accuracy: 0.6098\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.6640 - val_loss: 0.5363 - val_accuracy: 0.6098\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.6640 - val_loss: 0.5335 - val_accuracy: 0.6098\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.6640 - val_loss: 0.5303 - val_accuracy: 0.6098\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.6640 - val_loss: 0.5283 - val_accuracy: 0.6098\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.6741 - val_loss: 0.5262 - val_accuracy: 0.7073\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7536 - val_loss: 0.5240 - val_accuracy: 0.7073\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7576 - val_loss: 0.5222 - val_accuracy: 0.7073\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7536 - val_loss: 0.5206 - val_accuracy: 0.7154\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7556 - val_loss: 0.5174 - val_accuracy: 0.7154\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7637 - val_loss: 0.5150 - val_accuracy: 0.7236\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7678 - val_loss: 0.5123 - val_accuracy: 0.7236\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7719 - val_loss: 0.5111 - val_accuracy: 0.7154\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.7719 - val_loss: 0.5094 - val_accuracy: 0.7154\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7719 - val_loss: 0.5080 - val_accuracy: 0.7154\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7719 - val_loss: 0.5054 - val_accuracy: 0.7236\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7739 - val_loss: 0.5044 - val_accuracy: 0.7317\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7317\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7780 - val_loss: 0.5012 - val_accuracy: 0.7398\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7780 - val_loss: 0.5003 - val_accuracy: 0.7480\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7480\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7841 - val_loss: 0.4981 - val_accuracy: 0.7480\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7821 - val_loss: 0.4969 - val_accuracy: 0.7561\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7902 - val_loss: 0.4964 - val_accuracy: 0.7561\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7862 - val_loss: 0.4953 - val_accuracy: 0.7561\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7862 - val_loss: 0.4948 - val_accuracy: 0.7561\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7841 - val_loss: 0.4945 - val_accuracy: 0.7561\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7841 - val_loss: 0.4935 - val_accuracy: 0.7561\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7862 - val_loss: 0.4925 - val_accuracy: 0.7561\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7862 - val_loss: 0.4913 - val_accuracy: 0.7561\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7561\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7561\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7882 - val_loss: 0.4885 - val_accuracy: 0.7642\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7642\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.4864 - val_accuracy: 0.7724\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.4856 - val_accuracy: 0.7724\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7862 - val_loss: 0.4843 - val_accuracy: 0.7642\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.4836 - val_accuracy: 0.7724\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7862 - val_loss: 0.4829 - val_accuracy: 0.7724\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7862 - val_loss: 0.4822 - val_accuracy: 0.7724\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7862 - val_loss: 0.4809 - val_accuracy: 0.7724\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7862 - val_loss: 0.4816 - val_accuracy: 0.7724\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4810 - val_accuracy: 0.7724\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7841 - val_loss: 0.4791 - val_accuracy: 0.7805\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7821 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7862 - val_loss: 0.4778 - val_accuracy: 0.7724\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7923 - val_loss: 0.4772 - val_accuracy: 0.7724\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7923 - val_loss: 0.4763 - val_accuracy: 0.7724\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.4761 - val_accuracy: 0.7642\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4751 - val_accuracy: 0.7805\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7923 - val_loss: 0.4741 - val_accuracy: 0.7724\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7943 - val_loss: 0.4731 - val_accuracy: 0.7724\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7923 - val_loss: 0.4718 - val_accuracy: 0.7805\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7902 - val_loss: 0.4713 - val_accuracy: 0.7642\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7923 - val_loss: 0.4709 - val_accuracy: 0.7642\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7902 - val_loss: 0.4712 - val_accuracy: 0.7805\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7923 - val_loss: 0.4704 - val_accuracy: 0.7805\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7902 - val_loss: 0.4695 - val_accuracy: 0.7642\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7943 - val_loss: 0.4688 - val_accuracy: 0.7642\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7923 - val_loss: 0.4684 - val_accuracy: 0.7642\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7984 - val_loss: 0.4672 - val_accuracy: 0.7561\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7963 - val_loss: 0.4675 - val_accuracy: 0.7642\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7984 - val_loss: 0.4669 - val_accuracy: 0.7480\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7963 - val_loss: 0.4667 - val_accuracy: 0.7480\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7984 - val_loss: 0.4665 - val_accuracy: 0.7480\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7963 - val_loss: 0.4664 - val_accuracy: 0.7642\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7963 - val_loss: 0.4655 - val_accuracy: 0.7480\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7963 - val_loss: 0.4650 - val_accuracy: 0.7480\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7963 - val_loss: 0.4646 - val_accuracy: 0.7561\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7963 - val_loss: 0.4646 - val_accuracy: 0.7561\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7943 - val_loss: 0.4643 - val_accuracy: 0.7480\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7963 - val_loss: 0.4638 - val_accuracy: 0.7561\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7984 - val_loss: 0.4633 - val_accuracy: 0.7561\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7963 - val_loss: 0.4634 - val_accuracy: 0.7561\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8024 - val_loss: 0.4624 - val_accuracy: 0.7642\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7963 - val_loss: 0.4623 - val_accuracy: 0.7561\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7984 - val_loss: 0.4619 - val_accuracy: 0.7724\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75 (300.00 Byte)\n",
            "Trainable params: 75 (300.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep And Wide\n",
        "(Memiliki kombinasi banyak lapisan dan\n",
        "banyak neuron per lapisan)"
      ],
      "metadata": {
        "id": "WOAdzDIBlLma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dw = Sequential()\n",
        "model_dw.add(Dense(units=128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_dw.add(Dense(units=64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_dw.add(Dense(units=32, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_dw.add(Dense(units=16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_dw.add(Dense(units=8, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_dw.add(Dense(units=4, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_dw.add(Dense(units=2, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model_dw.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model_dw.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_dw.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "model_dw.summary()\n",
        "\n",
        "loss, accuracy = model_dw.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfa6toxMlOAl",
        "outputId": "93baf701-d215-4ab2-dd20-dd4e6e1666e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 19ms/step - loss: 0.6901 - accuracy: 0.6415 - val_loss: 0.6817 - val_accuracy: 0.7236\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.7475 - val_loss: 0.6535 - val_accuracy: 0.7398\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.7495 - val_loss: 0.6457 - val_accuracy: 0.7480\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.7821 - val_loss: 0.6296 - val_accuracy: 0.7561\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6268 - accuracy: 0.7902 - val_loss: 0.6244 - val_accuracy: 0.7724\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.8024 - val_loss: 0.6216 - val_accuracy: 0.7724\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.7984 - val_loss: 0.6234 - val_accuracy: 0.7480\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.8187 - val_loss: 0.6226 - val_accuracy: 0.7480\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.8126 - val_loss: 0.6204 - val_accuracy: 0.7480\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.8310 - val_loss: 0.6186 - val_accuracy: 0.7642\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.8269 - val_loss: 0.6123 - val_accuracy: 0.7724\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.8228 - val_loss: 0.6159 - val_accuracy: 0.7724\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.8350 - val_loss: 0.6009 - val_accuracy: 0.7642\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.8473 - val_loss: 0.6352 - val_accuracy: 0.7561\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.8473 - val_loss: 0.6469 - val_accuracy: 0.7561\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.8452 - val_loss: 0.6168 - val_accuracy: 0.7561\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.8513 - val_loss: 0.6358 - val_accuracy: 0.7154\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.8534 - val_loss: 0.6733 - val_accuracy: 0.7398\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.8473 - val_loss: 0.6322 - val_accuracy: 0.7480\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.8635 - val_loss: 0.7068 - val_accuracy: 0.7236\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.8493 - val_loss: 0.7024 - val_accuracy: 0.7236\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.8595 - val_loss: 0.6759 - val_accuracy: 0.7317\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.8615 - val_loss: 0.7469 - val_accuracy: 0.7398\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.8615 - val_loss: 0.7485 - val_accuracy: 0.7398\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.8554 - val_loss: 0.6895 - val_accuracy: 0.7236\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.8615 - val_loss: 0.7202 - val_accuracy: 0.7317\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.8778 - val_loss: 0.7889 - val_accuracy: 0.7480\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.8819 - val_loss: 0.8822 - val_accuracy: 0.7398\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8798 - val_loss: 0.7944 - val_accuracy: 0.7398\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8819 - val_loss: 0.8904 - val_accuracy: 0.7480\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8839 - val_loss: 0.8417 - val_accuracy: 0.7317\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8819 - val_loss: 0.8415 - val_accuracy: 0.7480\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8839 - val_loss: 0.7936 - val_accuracy: 0.7480\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8880 - val_loss: 0.8795 - val_accuracy: 0.7317\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8880 - val_loss: 0.8355 - val_accuracy: 0.7236\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8859 - val_loss: 1.0079 - val_accuracy: 0.7236\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8798 - val_loss: 0.8934 - val_accuracy: 0.7317\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8839 - val_loss: 0.9336 - val_accuracy: 0.7236\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8900 - val_loss: 1.0401 - val_accuracy: 0.7317\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8859 - val_loss: 0.8294 - val_accuracy: 0.7398\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8839 - val_loss: 0.8968 - val_accuracy: 0.7561\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8880 - val_loss: 0.9421 - val_accuracy: 0.7398\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8839 - val_loss: 0.9353 - val_accuracy: 0.7317\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8921 - val_loss: 1.0689 - val_accuracy: 0.7317\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8921 - val_loss: 1.0378 - val_accuracy: 0.7317\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8900 - val_loss: 0.9709 - val_accuracy: 0.7561\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8900 - val_loss: 0.9773 - val_accuracy: 0.7642\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8880 - val_loss: 0.9169 - val_accuracy: 0.7724\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8921 - val_loss: 1.0091 - val_accuracy: 0.7561\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8880 - val_loss: 1.0798 - val_accuracy: 0.7154\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8921 - val_loss: 1.0791 - val_accuracy: 0.7561\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8921 - val_loss: 1.0847 - val_accuracy: 0.7642\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8941 - val_loss: 1.0903 - val_accuracy: 0.7480\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8921 - val_loss: 0.9866 - val_accuracy: 0.7317\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8900 - val_loss: 1.1042 - val_accuracy: 0.7317\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8880 - val_loss: 0.9503 - val_accuracy: 0.7317\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8859 - val_loss: 1.2115 - val_accuracy: 0.7236\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8839 - val_loss: 1.0155 - val_accuracy: 0.7398\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8493 - val_loss: 0.8295 - val_accuracy: 0.7317\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8615 - val_loss: 0.9984 - val_accuracy: 0.7154\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8798 - val_loss: 0.9419 - val_accuracy: 0.7398\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8839 - val_loss: 0.8661 - val_accuracy: 0.7398\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8819 - val_loss: 0.9129 - val_accuracy: 0.7154\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8839 - val_loss: 1.0284 - val_accuracy: 0.7642\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8880 - val_loss: 0.9780 - val_accuracy: 0.7561\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8778 - val_loss: 0.9654 - val_accuracy: 0.7480\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8656 - val_loss: 0.9877 - val_accuracy: 0.7236\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8676 - val_loss: 0.8191 - val_accuracy: 0.7317\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8921 - val_loss: 1.1448 - val_accuracy: 0.7236\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8921 - val_loss: 1.0084 - val_accuracy: 0.7317\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8941 - val_loss: 1.1765 - val_accuracy: 0.7317\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8778 - val_loss: 1.0496 - val_accuracy: 0.7398\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8839 - val_loss: 1.0058 - val_accuracy: 0.7236\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8717 - val_loss: 0.9305 - val_accuracy: 0.7154\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8758 - val_loss: 0.9069 - val_accuracy: 0.7480\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8859 - val_loss: 1.1176 - val_accuracy: 0.7398\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8839 - val_loss: 1.0690 - val_accuracy: 0.7317\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.8880 - val_loss: 1.0494 - val_accuracy: 0.7398\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8880 - val_loss: 1.1221 - val_accuracy: 0.7317\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8880 - val_loss: 1.1143 - val_accuracy: 0.7398\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8880 - val_loss: 1.1340 - val_accuracy: 0.7398\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8880 - val_loss: 1.1729 - val_accuracy: 0.7317\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8880 - val_loss: 1.1541 - val_accuracy: 0.7480\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8880 - val_loss: 1.1162 - val_accuracy: 0.7561\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8880 - val_loss: 1.1294 - val_accuracy: 0.7561\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8880 - val_loss: 1.1556 - val_accuracy: 0.7480\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8880 - val_loss: 1.1769 - val_accuracy: 0.7480\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8880 - val_loss: 1.1901 - val_accuracy: 0.7480\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8880 - val_loss: 1.1834 - val_accuracy: 0.7561\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8880 - val_loss: 1.1894 - val_accuracy: 0.7561\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8880 - val_loss: 1.2124 - val_accuracy: 0.7480\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8880 - val_loss: 1.2305 - val_accuracy: 0.7480\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8880 - val_loss: 1.2431 - val_accuracy: 0.7480\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8880 - val_loss: 1.2441 - val_accuracy: 0.7480\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8880 - val_loss: 1.2465 - val_accuracy: 0.7480\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8880 - val_loss: 1.2531 - val_accuracy: 0.7398\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8880 - val_loss: 1.2599 - val_accuracy: 0.7398\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8880 - val_loss: 1.2614 - val_accuracy: 0.7480\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8880 - val_loss: 1.2717 - val_accuracy: 0.7480\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3397 - accuracy: 0.8880 - val_loss: 1.2834 - val_accuracy: 0.7398\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 128)               1152      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12201 (47.66 KB)\n",
            "Trainable params: 12201 (47.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6894 - accuracy: 0.7208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning Experiment"
      ],
      "metadata": {
        "id": "OhQqwPg2n8Rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Search"
      ],
      "metadata": {
        "id": "IKJrPW0qoMxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Narrow Shallow Model\n",
        "\n",
        "(Memiliki sedikit lapisan dan sedikit\n",
        "neuron per lapisan)"
      ],
      "metadata": {
        "id": "0cb2HFKbxy-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NarrowShallowModel(HyperModel):\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(units=hp.Int('units_1', min_value=4, max_value=32, step=4),\n",
        "                        activation='relu', input_shape=(self.input_shape,)))\n",
        "        model.add(Dense(units=hp.Int('units_2', min_value=4, max_value=16, step=4),\n",
        "                        activation='relu'))\n",
        "        # Lapisan output\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # Kompilasi model\n",
        "        model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "\n",
        "# Definisikan model hypermodel\n",
        "hypermodel = NarrowShallowModel(input_shape=X_train_scaled.shape[1])\n",
        "\n",
        "# Setup RandomSearch tuner\n",
        "tuner = RandomSearch(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='narrow_shallow_tuning'\n",
        ")\n",
        "\n",
        "# Jalankan pencarian hyperparameter\n",
        "tuner.search(X_train_scaled, y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Dapatkan model terbaik\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluasi model terbaik\n",
        "loss, accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Best model loss: {loss}, accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIKDBU0roPDe",
        "outputId": "68bd6570-3ae4-4efe-8e4c-4d921c854616"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.39024388790130615\n",
            "\n",
            "Best val_accuracy So Far: 0.8048780560493469\n",
            "Total elapsed time: 00h 00m 34s\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7338\n",
            "Best model loss: 0.5755832195281982, accuracy: 0.7337662577629089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Narrow Wide Model\n",
        "(Memiliki sedikit lapisan tetapi dengan\n",
        "lebih banyak neuron per lapisan)"
      ],
      "metadata": {
        "id": "X0R7s93dyKUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NarrowWideModel(HyperModel):\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(units=hp.Int('units_1', min_value=64, max_value=512, step=64),\n",
        "                        activation='relu', input_shape=(self.input_shape,)))\n",
        "        model.add(Dense(units=hp.Int('units_2', min_value=16, max_value=128, step=16),\n",
        "                        activation='relu'))\n",
        "        # Lapisan output\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # Kompilasi model\n",
        "        model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "\n",
        "# Definisikan model hypermodel\n",
        "hypermodel = NarrowWideModel(input_shape=X_train_scaled.shape[1])\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='narrow_wide_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(X_train_scaled, y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Dapatkan model terbaik\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluasi model terbaik\n",
        "loss, accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Best model loss: {loss}, accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLDJxdLFyUBL",
        "outputId": "ad550859-5c16-4a02-c09f-6b22a789d4b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 06s]\n",
            "val_accuracy: 0.7560975551605225\n",
            "\n",
            "Best val_accuracy So Far: 0.7886179089546204\n",
            "Total elapsed time: 00h 00m 40s\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7338\n",
            "Best model loss: 0.5203132033348083, accuracy: 0.7337662577629089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deep Shalow Model\n",
        "(Memiliki banyak lapisan tetapi sedikit\n",
        "neuron per lapisan)"
      ],
      "metadata": {
        "id": "YrEPW_AXzX0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepShallowModel(HyperModel):\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        # Lapisan input dan lapisan tersembunyi pertama dengan unit lebih banyak (deep)\n",
        "        model.add(Dense(\n",
        "            units=hp.Int('units_1', min_value=128, max_value=512, step=64),\n",
        "            activation='relu',\n",
        "            input_shape=(self.input_shape,)\n",
        "        ))\n",
        "        # Menambahkan beberapa lapisan tersembunyi tambahan dengan unit bertahap lebih sedikit (shallow)\n",
        "        for i in range(2, hp.Int('num_layers', 2, 4)):  # Menambahkan 1-2 lapisan tersembunyi tambahan\n",
        "            model.add(Dense(\n",
        "                units=hp.Int(f'units_{i}', min_value=16, max_value=128, step=16, parent_name='units_1', parent_values=[128, 192, 256, 320, 384, 448, 512]),\n",
        "                activation='relu'\n",
        "            ))\n",
        "        # Lapisan output\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # Kompilasi model\n",
        "        model.compile(\n",
        "            optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "\n",
        "hypermodel = DeepShallowModel(input_shape=X_train_scaled.shape[1])\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='deep_shallow_tuning',\n",
        "    project_name='diabetes_prediction_deep_shallow'\n",
        ")\n",
        "\n",
        "tuner.search(X_train_scaled, y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "loss, accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Best model loss: {loss}, accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbSLXmhazhtl",
        "outputId": "8129d642-56e3-4b05-ccbf-3c534e046595"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from deep_shallow_tuning/diabetes_prediction_deep_shallow/tuner0.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7662\n",
            "Best model loss: 0.4921472668647766, accuracy: 0.7662337422370911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deep Wide Model\n",
        "(Memiliki kombinasi banyak lapisan dan\n",
        "banyak neuron per lapisan)"
      ],
      "metadata": {
        "id": "ACZ0w3mP0hVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepAndWideModel(HyperModel):\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        # Lapisan input dan lapisan tersembunyi pertama yang \"wide\"\n",
        "        model.add(Dense(\n",
        "            units=hp.Int('units_1', min_value=128, max_value=512, step=64),\n",
        "            activation='relu',\n",
        "            input_shape=(self.input_shape,)\n",
        "        ))\n",
        "        # Menambahkan beberapa lapisan tersembunyi \"deep\"\n",
        "        for i in range(2, hp.Int('num_layers', 3, 5)):  # Menambahkan 2-4 lapisan tersembunyi tambahan\n",
        "            model.add(Dense(\n",
        "                units=hp.Int(f'units_{i}', min_value=64, max_value=256, step=32),\n",
        "                activation='relu'\n",
        "            ))\n",
        "        # Lapisan output\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # Kompilasi model\n",
        "        model.compile(\n",
        "            optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "\n",
        "hypermodel = DeepAndWideModel(input_shape=X_train_scaled.shape[1])\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='deep_wide_tuning',\n",
        "    project_name='diabetes_prediction_deep_wide'\n",
        ")\n",
        "\n",
        "# Mulai pencarian hyperparameter\n",
        "tuner.search(X_train_scaled, y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Dapatkan dan evaluasi model terbaik\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "loss, accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Best model loss: {loss}, accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgL7u_-v0nWX",
        "outputId": "70395b30-4622-466b-d790-7de37baf90a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from deep_wide_tuning/diabetes_prediction_deep_wide/tuner0.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7578 - accuracy: 0.7143\n",
            "Best model loss: 0.7578365802764893, accuracy: 0.7142857313156128\n"
          ]
        }
      ]
    }
  ]
}